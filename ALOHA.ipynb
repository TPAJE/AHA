{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALOHA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ALOHA - AI-assisted Haemorrhage Analysis\n",
        "\n",
        "This Google Colabs allows you to run an instance of the ALOHA tool until we can find a more permanent hosting solution for the tool.\n",
        "\n",
        "We have included an example image [here](https://raw.githubusercontent.com/laprade117/ALOHA/main/example_image.jpg).\n",
        "\n",
        "**Usage:**\n",
        "1. First, you need to connect to Google's compute servers. Click the 'Connect' button in the top right corner of the page.\n",
        "\n",
        "2. We can now run the notebook and start the tool. In the menu at the top of the page go to Runtime -> Restart and run all. This will force the notebook to restart and then run all code blocks below. If the menu is hidden, click the down arrow in the top right corner to make it visible again. If the 'Restart and run all' option is grayed out, it means you forgot Step 1. Click 'Yes' if it asks you if you are sure you want to do this. If it warns you that this notebook is not authored by Google, click 'Run anyway'. \n",
        "\n",
        "3. After a short wait a link should appear at the bottom of this page (scroll all the way down) that looks something like this:\n",
        "\n",
        "        your url is: http://aloha-30916.loca.lt\n",
        "\n",
        "  Although the number after \"aloha\" will likely be different. Click the link. It may bring you to localtunnel's startup page. Press the \"Click to Continue\" button to open the tool."
      ],
      "metadata": {
        "id": "wcR6hZK8ACZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell downloads the tool from Github, creates a models/ directory and \n",
        "# sets ALOHA/ as the current working directory.\n",
        "%%capture\n",
        "!git clone https://github.com/laprade117/ALOHA.git\n",
        "%cd ALOHA\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "2StNbdxdpj5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell downloads the inference models from Github.\n",
        "%%capture\n",
        "!wget -b -O models/unet_inference_0.ckpt https://github.com/laprade117/ALOHA/releases/download/inference-models/unet_inference_0.ckpt\n",
        "!wget -b -O models/unet_inference_1.ckpt https://github.com/laprade117/ALOHA/releases/download/inference-models/unet_inference_1.ckpt\n",
        "!wget -b -O models/unet_inference_2.ckpt https://github.com/laprade117/ALOHA/releases/download/inference-models/unet_inference_2.ckpt\n",
        "!wget -b -O models/unet_inference_3.ckpt https://github.com/laprade117/ALOHA/releases/download/inference-models/unet_inference_3.ckpt\n",
        "!wget -b -O models/unet_inference_4.ckpt https://github.com/laprade117/ALOHA/releases/download/inference-models/unet_inference_4.ckpt"
      ],
      "metadata": {
        "id": "rTyH-IwAsbKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTS2EKckpd4t"
      },
      "outputs": [],
      "source": [
        "# This cell installs the required Python packages for the tool.\n",
        "%%capture\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell runs the tool. Look for the URL in the output below.\n",
        "!streamlit run app.py & npx localtunnel --port 8501 --subdomain aloha-$RANDOM"
      ],
      "metadata": {
        "id": "_QMoCOMzs-ql"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
